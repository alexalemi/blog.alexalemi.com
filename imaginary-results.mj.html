<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name='viewport' content='width=device-width, initial-scale=1.0' /> 
    <title>blog.alexalemi.com The Method of Imaginary Results</title>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-F5SW43T5NT"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-F5SW43T5NT');
    </script>

		<!-- favicon stuff -->
		<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
		<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
		<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
		<link rel="manifest" href="/site.webmanifest">
		<meta name="msapplication-TileColor" content="#da532c">
		<meta name="theme-color" content="#ffffff">


    <!-- RSS Feed -->
    <link rel="alternate" type="application/rss+xml" title="blog.AlexAlemi.com" href="https://blog.alexalemi.com/rss.xml" />

    <!-- Fonts -->
    <script type="text/javascript">
        WebFontConfig = {
            google: { families: [ 'Muli', 'Lato' ] }
        };
        (function() {
            var wf = document.createElement('script');
            wf.src = ('https:' == document.location.protocol ? 'https' : 'http') + '://ajax.googleapis.com/ajax/libs/webfont/1/webfont.js';
            wf.type = 'text/javascript';
            wf.async = 'true';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(wf, s);
        })();
    </script>

    <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        processEscapes: true
      }};
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <!-- Inline CSS -->
    <link rel="stylesheet" type="text/css" href="assets/style.css"/>
</head>

<body>


  <header>
    <h3>Alex Alemi's Blog</h3>
    <nav>
      <a href='https://blog.alexalemi.com' />Index</a> |
      <a href='https://alexalemi.com' />About Me</a> | 
      <a rel="alternate" type="application/rss+xml" title="blog.AlexAlemi.com" href="https://blog.alexalemi.com/rss.xml" />RSS</a>
    </nav>
  </header>

  <article>
		<h1>The Method of Imaginary Results</h1>
		<p>Alexander A. Alemi. <time datetime='2023-11-30'>2023-11-30</time></p>
    <div class="content">
    <p>Performing Bayesian inference requires a full joint distribution over both our
data and parameters $p(D,\theta)$.  In the usual way of doing things, we
specify that joint distribution by providing two pieces: a likelihood
$p(D|\theta)$ that specifies how we believe the data would be
generated if we happened to know the exact parameter values and some prior
$p(\theta)$ over parameters that represents our state of belief about what the
parameters are before we look at any data.</p>
<p>Most people don't have any deep philosophical issues with specifying a
likelihood $p(D|\theta)$. We're aware that our likelihoods might not be
perfect, that they are some approximation of what is happening in the real
world. Still, we have opinions about them, we feel as though we can reason about
whether a given likelihood is good or bad for some situation.</p>
<p>I believe I can model a series of $D$ heads in $N$ coin flips with a <a href="https://en.wikipedia.org/wiki/Binomial_distribution">Binomial
likelihood</a> for instance,
and I don't really have any qualms about that.
I might decide to model the heights of my pea plants with a <a href="https://en.wikipedia.org/wiki/Normal_distribution">Normal
Distribution</a> or perform a
<a href="https://en.wikipedia.org/wiki/Linear_regression">linear fit</a> to some data, or
do image classification with some <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural
network</a> or
<a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)">transformer</a>. In any case, I often have a good idea of what I should use as a likelihood $p(D|\theta)$.</p>
<aside><sup id="yesterday">1</sup>
This quote is often attributed to Lindley (1970), but I see no such occurance in that work. Looking around the original quote appears to be "Today's posterior is tomorrow's prior." From <a href="https://people.umass.edu/stanek/pubhlth892d/Lindley-The-Statist-2000.pdf"><i>The Philosophy of Statistics</i></a> by Dennis V Lindley, The Statistician 2000.  There do not appear to be any earlier occurrences of "today's prior" used in the sense of Bayesian inference that appear on Google Scholar.
</aside>
<p>Choosing the prior $p(\theta)$ is what all the fuss is about.  This is the part that raises various philosophical issues.  This is the part that, if we are being honest, is much harder.  What do I believe the bias of a coin is before I ever flip the coin?  I'm not really sure to be honest.  In many contexts I might have previously done some experiments, in which case I could use yesterday's posterior as today's prior.<sup><a href="#yesterday">1</a></sup></p>
<aside><sup id="indifference">2</sup>
Originally coined the <i>principle of insufficient reason</i> by Johannes on Kries, John Maynard Keyes renamed it the <i>principle of indifference</i>. <a href="https://en.wikipedia.org/wiki/Principle_of_indifference#History">[wiki]</a>
</aside>
<aside><sup id="jaynes-priors">3</sup>
    <a href="https://bayes.wustl.edu/etj/articles/prior.pdf"><i>Prior Probabilities</i></a> by Edwin T. Jaynes. 1968
</aside>
<aside><sup id="reference">4</sup>
See for instance <a href="https://arxiv.org/pdf/0904.0156.pdf"><i>A Formal Definition of Reference Priors</i></a> by Berger, Bernardo and Sun.  For a more modern take I really like see <a href="https://arxiv.org/abs/1705.01166"><i>Maximizing the information learned from finite data selects a simple model</i></a> by Mattingly et al. and <a href="https://arxiv.org/abs/2205.03343"><i>Far from Asymptopia</i></a> by Abbott and Machta.
</aside>
<p>However lacking previous experiments, I often feel at a loss. There are many frameworks for designing priors that people have proposed.  Laplace originally motivated a flat prior for the Bernoulli likelihood by appealing to the <em>principle of indifference</em>.<sup><a href="#indifference">2</a></sup>
<a href="https://en.wikipedia.org/wiki/Jeffreys_prior">Jeffreys</a> taught us how to build priors that were reparameterization-independent.
Jaynes would argue for choosing priors by appealing to symmetries.<sup><a href="#jaynes-priors">3</a></sup> Bernardo suggested choosing priors to maximize the information you extract from data, so called <i>reference priors</i>.<sup><a href="#reference">4</a></sup> Gelman and friends tout <i>weakly informative priors</i>.
There are even whole <a href="https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations">lists of common recommendations</a>.</p>
<p>What if we didn't have to choose a prior directly?</p>
<h2>The Method of Imaginary Results</h2>
<aside><sup id="gelman-speed">5</sup>
See the first page of the nice little paper <a href="http://www.stat.columbia.edu/~gelman/research/published/GelmanSpeed.pdf"><i>Characterizing a Joint Probability Distribution By Conditionals</i></a> by Gelman and Speed, 1991.
</aside>
<p>Enter <em>the method of imaginary results</em>.  It turns out<sup><a href="#gelman-speed">5</a></sup> that we can uniquely characterize a joint distribution in a different way.  Specifying a likelihood $L(D|\theta)$ and a prior $\pi(\theta)$ uniquely characterizes the joint $p(D,\theta) = L(D|\theta)\pi(\theta)$.  You know what else uniquely characterizes the joint? Specifying a likelihood $L(D|\theta)$ and some <em>hypothetical</em> posterior $q(\theta|D_0)$. The corresponding unique joint $p(\theta,D)$ is given by:</p>
<p>$$ p(\theta, D) \propto L(D|\theta) \frac{q(\theta|D_0)}{L(D_0|\theta)} = \frac{ L(D|\theta) \frac{q(\theta|D_0)}{L(D_0|\theta)} }{\int d\theta\, L(D|\theta) \frac{q(\theta|D_0)}{L(D_0|\theta)}}.  $$</p>
<p>Which naturally satisfies the two inputs we provided:
$$ p(D|\theta) = L(D|\theta) \qquad p(\theta|D_0) = q(\theta|D_0). $$</p>
<p>This flips the problem on its head.  We no longer have to specify a <em>prior</em>.  Instead we can specify a <em>hypothetical posterior</em>.  We can say what we would believe, if, hypothetically we had observed some dataset $D_0$.</p>
<p>I think that this is an easier task to do.  It is easier for me to reason about what beliefs I should hypothetically hold in like of some data than it is for me to reason about what I believe independent of any data.</p>
<h2>Coin Example</h2>
<p>Let's work a simple example of a coin flip.  I believe I can model a coin as being a simple Bernoulli process. There is some probability $\theta$ that the coin will land heads and each flip is independent and identically distributed.  Therefore I can model observing $H$ heads out of sequence of $N$ flips with a <a href="https://en.wikipedia.org/wiki/Binomial_distribution">Binomial Likelihood</a>:</p>
<p>$$ L({H,N}|\theta) = { N \choose H} \theta^H (1- \theta)^{N-H} $$</p>
<p>Now, we imagine I actually observe some sequence of coin flips, let's say 6 out of 10 flips were heads. Now what should I believe about the bias of my coin?  To answer this I need to specify a prior belief I have about the bias of the coin.  In most textbook examples, that prior is taken to be uniform $p(\theta) = 1$, saying that our prior belief is that it is equally likely that the coin should have a bias in an interval $\theta + \delta \theta$ for any $\theta$, i.e. this prior says its just as likely the bias of the coin is between 0.1 and 0.2 as it is that it is between 0.5 and 0.6.</p>
<p>Alternatively, I could take Jeffrey's advice and adopt a non-informative prior that is reparameterization independent, or I could try to adopt Gelman's advice and start with an informative prior concentrated near fairness. Below is a representation of these three standard choices where the prior is shown in blue and the posterior from 6 heads out of 10 flips is shown in orange.</p>
<figure id="#standard-priors" class="right">
  <center>
  <img width="95%" src="figures/standard-coin-priors.svg"
    alt="A visualization of some standard prior and posterior pairs, a uniform prior, jeffrey's prior and a weakly informative prior.">
  <figcaption>
  Figure 1. Some standard textbook priors and the resulting posterior for 6 heads out of 10 coin flips.
  </figcaption>
  </center>
</figure>
<p>These are convenient mathematically and make for an easy problems to solve for a homework exercises, but they aren't realistic.  If we are being honest, we tend to expect that coins we encounter in the real world and very nearly fair.<sup><a href="#fiarness">6</a></sup>.  We could therefore start with a prior that is concentrated near fair, but how do we assign a meaningful width to that distribution?  And if we're being honest, I've encountered trick coins in my days, double headed and doubled tailed coins and if some wierdo walks up to me and asks me to start predicting a whole sequence of coin flips I shouldn't discount the possiblity they are trying to play me for a fool.</p>
<aside><sup id="fairness">6</sup>
Despite there being <a href="https://statweb.stanford.edu/~cgates/PERSI/papers/dyn_coin_07.pdf">arguments</a> and <a href="https://arxiv.org/abs/2310.04153">strong evidence</a> that there is a <i>dynamical</i> bias, meaning that coins tend to land on the same side they start as showing up in human flips.
</aside>
<p>As this stage, trying to adjust the parameters of our <em>prior</em> without any evidence or data is difficult.  I have a hard time talking to my gut to decide what I should set my prior beliefs to apropro of <em>nothing</em>.  Instead, let's try to invoke the method of imaginary results and imagine some hypothetical dataset and probe our beliefs.  Imagine we've just observed 10 coin flips, and all 10 of them were heads!  What do you believe now?  Now that I've hypothesized a dataset I have an easrier time talking to my gut.</p>
<p>In this scenario, I feel as though I would place a reasonable probability on the coin being unfair, let's say 50%.  At the same time, I think I would still place a reasonable probability on the coin being <em>exactly</em> fair, let's say 25%.  The remaining 25% probability I would want to spread around but biased towards heads, for that let's use a $\operatorname{Beta}(11,1)$ distribution or $11\, \theta^{10}$.  I've attempted to visualize this distribution below.<a href="#deltas"><sup>7</sup></a></p>
<figure id="#imaginary-result-coin" class="right">
  <center>
  <img width="95%" src="figures/imaginary-result.svg"
    alt="A mixture of 25\% mass on 0.5, 50\% mass on 1.0 and 25\% mass on a Beta(11, 1).">
  <figcaption>
  Figure 2. My attempt at illiciting an imaginary result of a posterior I'm comfortable with if I were to observe 10 heads in a row from a coin.
  </figcaption>
  </center>
</figure>
<aside><sup id="deltas">7</sup>
I don't know a good way to visualize probability distributions with delta components. I like the idea of putting vertical lines with balls at the top, but I don't know how to demonstrate how much mass the deltas have in reference to the rest of the density, it doesn't feel like there would be a good choice for the right scale to use.  Here I've done something I'm not proud of but I feel like is honest at least, I've just discretized the distribution into 100 bins, so you can see both the width and the corresponding height, I choose a fairly course discretization so that you can still see the bit of the Beta underneath the spikes.
</aside>
<p>Or in equation form:</p>
<p>$$ q(\theta|D_0) = \frac 12 \delta(\theta -1 ) + \frac 14 \delta\left(\theta - \frac 12 \right) + \frac {11} 4 \theta^{10} $$</p>
<p>Once we've specified this imaginary result, we have everything we need to form a posterior for our original problem with 6 heads out of 10 flips.</p>
<p>$$\begin{align}
p(\theta|D) &amp;\propto L(D|\theta) \frac{q(\theta|D_0)}{L(D_0|\theta)} \\
&amp;\propto 210 \theta^6 (1-\theta)^4 \frac{\frac 14 \delta\left(\theta - \frac 12 \right) + \frac 12 \delta(\theta - 1) + \frac{11}{4} \theta^{10}}{\theta^{10}} \\
&amp;= \frac{210}{211} \delta\left(\theta -\frac 12 \right) + \frac{1}{211} \left( 2310 \theta^{6} (1-\theta)^4 \right)
\end{align} $$</p>
<figure id="#imaginary-result-posterior-coin" class="right">
  <center>
  <img width="95%" src="figures/imaginary-result-posterior.svg"
    alt="A mixture of 99.5\% mass on 0.5, 0.50\% mass on a Beta(7, 5).">
  <figcaption>
  Figure 3. The posterior I get from my illicited imaginary posterior if I actually observe 6 heads and 4 tails. The blue curve is the true posterior, the dashed orange is a blown up version of the small residual component.
  </figcaption>
  </center>
</figure>
<p>The posterior we find is 99.5% probability on the coin being exactly fair, and 0.5% probability assigned to a $\operatorname{Beta}(7,5)$ type posterior, which is buried in the true form above, but I've blown up in the dashed line so you can see its shape.  This posterior has a very heavy weight on the coin being exactly fair, which I think is reflective of my actual beliefs but I would have had difficulty specifying in terms of a prior.  Instead, if I imagine the coin coming up heads 10 times in a row, the fact that I wanted to still give the coin a 25% chance of being fair is obviously mathematically equivalent to me having a 98.7% prior belief the coin is fair, but I feel as though I have a much higher sensitivity to the right number when I express this as a hypothetical posterior.</p>
<p>The method of imaginary results let's us ask ourselves what we would believe in light of some data, rather than ask us to express what we believe apropos of <em>nothing</em>.  I think this helps resolve some of the philosophical issues have with prior selection in Bayesian inference.</p>
 
    </div>
  </article>

  <script src="https://giscus.app/client.js"
        data-repo="alexalemi/blog.alexalemi.com"
        data-repo-id="MDEwOlJlcG9zaXRvcnkyNjk2OTU4MzU="
        data-category="Announcements"
        data-category-id="DIC_kwDOEBM7W84B_4Ke"
        data-mapping="pathname"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-theme="light"
        data-lang="en"
        crossorigin="anonymous"
        async>
  </script>

  <footer>
    <!-- <p>
    &copy; 2020 Alexander A. Alemi
    </p>
    -->
  </footer>



</body>
</html>